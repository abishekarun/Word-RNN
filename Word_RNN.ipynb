{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_RNN.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "2ZIodA5PBxfL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a4f27f5-1d7f-4a35-d27d-9173997cf674",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524294164880,
          "user_tz": 420,
          "elapsed": 1350,
          "user": {
            "displayName": "Arun Rajendran",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100710189298922321078"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import string\n",
        "from collections import namedtuple\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Dense,LSTM,Dropout,Embedding"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xyBzP21HBxfS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Read the data\n",
        "with open('The_Da_Vinci_Code.txt', encoding=\"utf8\", errors='ignore') as f:\n",
        "    text=f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jJnmlvka2L9j",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def clean_doc(doc):\n",
        "\t# replace '--' with a space ' '\n",
        "\tdoc = doc.replace('--', ' ')\n",
        "\t# split into tokens by white space\n",
        "\ttokens = doc.split()\n",
        "\t# remove punctuation from each token\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\ttokens = [w.translate(table) for w in tokens]\n",
        "\t# remove remaining tokens that are not alphabetic\n",
        "\ttokens = [word for word in tokens if word.isalpha()]\n",
        "\t# make lower case\n",
        "\ttokens = [word.lower() for word in tokens]\n",
        "\treturn tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BFWJKRRP2TBO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Get text as tokens\n",
        "tokens = clean_doc(text)\n",
        "# vocabulary size\n",
        "total_words = len(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9viEn8vfCT2M",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Length of unique tokens\n",
        "unique_words =len(set(tokens))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OnCZmHdDNtns",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Integer encode the tokens\n",
        "vocab = sorted(set(tokens))\n",
        "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
        "int_to_vocab = dict(enumerate(vocab))\n",
        "encoded = np.array([vocab_to_int[c] for c in tokens], dtype=np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LbONRQFWw2G1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.save('int_to_vocab.npy', int_to_vocab)\n",
        "np.save('vocab_to_int.npy', vocab_to_int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jVSDm7xiN04R",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "baab2ef8-e75c-40f5-c272-6daeda46be09",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524294168576,
          "user_tz": 420,
          "elapsed": 268,
          "user": {
            "displayName": "Arun Rajendran",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100710189298922321078"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tokens[:20]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'da',\n",
              " 'vinci',\n",
              " 'code',\n",
              " 'dan',\n",
              " 'brown',\n",
              " 'for',\n",
              " 'blythe',\n",
              " 'again',\n",
              " 'more',\n",
              " 'than',\n",
              " 'ever',\n",
              " 'prologue',\n",
              " 'louvre',\n",
              " 'museum',\n",
              " 'paris',\n",
              " 'pm',\n",
              " 'renowned',\n",
              " 'curator',\n",
              " 'jacques']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "1S-YtU_7Tm-m",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "seq_len = 10\n",
        "X=[]\n",
        "y = np.zeros((total_words-seq_len,unique_words), dtype=np.bool)\n",
        "for i in range(seq_len,total_words):\n",
        "  words_in = tokens[i-seq_len:i]\n",
        "  word_out = tokens[i]\n",
        "  X.append([vocab_to_int[word] for word in words_in])\n",
        "  y[i-seq_len,vocab_to_int[word_out]]=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TISXicO3XnSU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X = np.asarray(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "00SaURBRezTt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6f7a3e9-af44-40a9-b84d-d29a8c5e4fe6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524294171523,
          "user_tz": 420,
          "elapsed": 297,
          "user": {
            "displayName": "Arun Rajendran",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100710189298922321078"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137995, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "AwyeV3oNQbRH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 7106
        },
        "outputId": "9bfa457a-77f1-4699-aaa4-89c137f5870c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524300016838,
          "user_tz": 420,
          "elapsed": 5845148,
          "user": {
            "displayName": "Arun Rajendran",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100710189298922321078"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(X.shape[0], 10, input_length=seq_len))\n",
        "model.add(LSTM(512))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "print(model.summary())\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"Adam\")\n",
        "# fit model\n",
        "filepath='best_model.h5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "model.fit(X,y, batch_size=128, epochs=100,callbacks=[checkpoint])\n",
        "# save the model to file"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 10, 10)            1379950   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 512)               1071104   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 11495)             5896935   \n",
            "=================================================================\n",
            "Total params: 8,347,989\n",
            "Trainable params: 8,347,989\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            " 13312/137995 [=>............................] - ETA: 1:06 - loss: 7.4697"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 60s 433us/step - loss: 6.9497\n",
            "\n",
            "Epoch 00001: loss improved from inf to 6.94970, saving model to best_model.h5\n",
            "Epoch 2/100\n",
            " 15616/137995 [==>...........................] - ETA: 51s - loss: 6.6987"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 423us/step - loss: 6.6756\n",
            "\n",
            "Epoch 00002: loss improved from 6.94970 to 6.67559, saving model to best_model.h5\n",
            "Epoch 3/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 6.5147"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 423us/step - loss: 6.4997\n",
            "\n",
            "Epoch 00003: loss improved from 6.67559 to 6.49972, saving model to best_model.h5\n",
            "Epoch 4/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 6.3252"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 6.3159\n",
            "\n",
            "Epoch 00004: loss improved from 6.49972 to 6.31588, saving model to best_model.h5\n",
            "Epoch 5/100\n",
            " 16512/137995 [==>...........................] - ETA: 51s - loss: 6.1066"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 423us/step - loss: 6.1148\n",
            "\n",
            "Epoch 00005: loss improved from 6.31588 to 6.11483, saving model to best_model.h5\n",
            "Epoch 6/100\n",
            " 16512/137995 [==>...........................] - ETA: 51s - loss: 5.9440"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 5.9226\n",
            "\n",
            "Epoch 00006: loss improved from 6.11483 to 5.92262, saving model to best_model.h5\n",
            "Epoch 7/100\n",
            " 16384/137995 [==>...........................] - ETA: 51s - loss: 5.7196"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 423us/step - loss: 5.7385\n",
            "\n",
            "Epoch 00007: loss improved from 5.92262 to 5.73850, saving model to best_model.h5\n",
            "Epoch 8/100\n",
            " 16512/137995 [==>...........................] - ETA: 51s - loss: 5.5093"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 423us/step - loss: 5.5592\n",
            "\n",
            "Epoch 00008: loss improved from 5.73850 to 5.55917, saving model to best_model.h5\n",
            "Epoch 9/100\n",
            " 16384/137995 [==>...........................] - ETA: 52s - loss: 5.2951"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 425us/step - loss: 5.3756\n",
            "\n",
            "Epoch 00009: loss improved from 5.55917 to 5.37556, saving model to best_model.h5\n",
            "Epoch 10/100\n",
            " 16512/137995 [==>...........................] - ETA: 50s - loss: 5.1162"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 419us/step - loss: 5.1883\n",
            "\n",
            "Epoch 00010: loss improved from 5.37556 to 5.18827, saving model to best_model.h5\n",
            "Epoch 11/100\n",
            " 16256/137995 [==>...........................] - ETA: 50s - loss: 4.9017"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 57s 414us/step - loss: 4.9867\n",
            "\n",
            "Epoch 00011: loss improved from 5.18827 to 4.98666, saving model to best_model.h5\n",
            "Epoch 12/100\n",
            " 17408/137995 [==>...........................] - ETA: 50s - loss: 4.6877"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 57s 415us/step - loss: 4.7780\n",
            "\n",
            "Epoch 00012: loss improved from 4.98666 to 4.77804, saving model to best_model.h5\n",
            "Epoch 13/100\n",
            " 16768/137995 [==>...........................] - ETA: 50s - loss: 4.4428"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 57s 415us/step - loss: 4.5665\n",
            "\n",
            "Epoch 00013: loss improved from 4.77804 to 4.56654, saving model to best_model.h5\n",
            "Epoch 14/100\n",
            " 17152/137995 [==>...........................] - ETA: 50s - loss: 4.1874"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 417us/step - loss: 4.3529\n",
            "\n",
            "Epoch 00014: loss improved from 4.56654 to 4.35286, saving model to best_model.h5\n",
            "Epoch 15/100\n",
            " 16896/137995 [==>...........................] - ETA: 50s - loss: 3.9738"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 420us/step - loss: 4.1423\n",
            "\n",
            "Epoch 00015: loss improved from 4.35286 to 4.14227, saving model to best_model.h5\n",
            "Epoch 16/100\n",
            " 16512/137995 [==>...........................] - ETA: 51s - loss: 3.7487"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 419us/step - loss: 3.9502\n",
            "\n",
            "Epoch 00016: loss improved from 4.14227 to 3.95022, saving model to best_model.h5\n",
            "Epoch 17/100\n",
            " 16256/137995 [==>...........................] - ETA: 50s - loss: 3.5863"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 419us/step - loss: 3.7585\n",
            "\n",
            "Epoch 00017: loss improved from 3.95022 to 3.75852, saving model to best_model.h5\n",
            "Epoch 18/100\n",
            " 16256/137995 [==>...........................] - ETA: 50s - loss: 3.4145"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 418us/step - loss: 3.5951\n",
            "\n",
            "Epoch 00018: loss improved from 3.75852 to 3.59512, saving model to best_model.h5\n",
            "Epoch 19/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 3.2471"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 420us/step - loss: 3.4352\n",
            "\n",
            "Epoch 00019: loss improved from 3.59512 to 3.43515, saving model to best_model.h5\n",
            "Epoch 20/100\n",
            " 16384/137995 [==>...........................] - ETA: 51s - loss: 3.1104"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 420us/step - loss: 3.2901\n",
            "\n",
            "Epoch 00020: loss improved from 3.43515 to 3.29009, saving model to best_model.h5\n",
            "Epoch 21/100\n",
            " 16512/137995 [==>...........................] - ETA: 51s - loss: 3.0080"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 420us/step - loss: 3.1577\n",
            "\n",
            "Epoch 00021: loss improved from 3.29009 to 3.15767, saving model to best_model.h5\n",
            "Epoch 22/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 2.8620"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 424us/step - loss: 3.0366\n",
            "\n",
            "Epoch 00022: loss improved from 3.15767 to 3.03658, saving model to best_model.h5\n",
            "Epoch 23/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 2.7576"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 2.9206\n",
            "\n",
            "Epoch 00023: loss improved from 3.03658 to 2.92057, saving model to best_model.h5\n",
            "Epoch 24/100\n",
            " 16384/137995 [==>...........................] - ETA: 51s - loss: 2.6557"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 2.8244\n",
            "\n",
            "Epoch 00024: loss improved from 2.92057 to 2.82436, saving model to best_model.h5\n",
            "Epoch 25/100\n",
            " 16512/137995 [==>...........................] - ETA: 51s - loss: 2.5506"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 423us/step - loss: 2.7222\n",
            "\n",
            "Epoch 00025: loss improved from 2.82436 to 2.72216, saving model to best_model.h5\n",
            "Epoch 26/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 2.4360"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 424us/step - loss: 2.6323\n",
            "\n",
            "Epoch 00026: loss improved from 2.72216 to 2.63233, saving model to best_model.h5\n",
            "Epoch 27/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 2.3811"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 424us/step - loss: 2.5524\n",
            "\n",
            "Epoch 00027: loss improved from 2.63233 to 2.55237, saving model to best_model.h5\n",
            "Epoch 28/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 2.2838"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 424us/step - loss: 2.4747\n",
            "\n",
            "Epoch 00028: loss improved from 2.55237 to 2.47470, saving model to best_model.h5\n",
            "Epoch 29/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 2.2339"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 425us/step - loss: 2.4057\n",
            "\n",
            "Epoch 00029: loss improved from 2.47470 to 2.40573, saving model to best_model.h5\n",
            "Epoch 30/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 2.1487"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 2.3313\n",
            "\n",
            "Epoch 00030: loss improved from 2.40573 to 2.33130, saving model to best_model.h5\n",
            "Epoch 31/100\n",
            " 16128/137995 [==>...........................] - ETA: 52s - loss: 2.0890"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 424us/step - loss: 2.2671\n",
            "\n",
            "Epoch 00031: loss improved from 2.33130 to 2.26708, saving model to best_model.h5\n",
            "Epoch 32/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 2.0480"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 2.2085\n",
            "\n",
            "Epoch 00032: loss improved from 2.26708 to 2.20849, saving model to best_model.h5\n",
            "Epoch 33/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.9915"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 421us/step - loss: 2.1517\n",
            "\n",
            "Epoch 00033: loss improved from 2.20849 to 2.15168, saving model to best_model.h5\n",
            "Epoch 34/100\n",
            " 16512/137995 [==>...........................] - ETA: 50s - loss: 1.9324"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 420us/step - loss: 2.0956\n",
            "\n",
            "Epoch 00034: loss improved from 2.15168 to 2.09556, saving model to best_model.h5\n",
            "Epoch 35/100\n",
            " 16128/137995 [==>...........................] - ETA: 52s - loss: 1.8974"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 2.0544\n",
            "\n",
            "Epoch 00035: loss improved from 2.09556 to 2.05444, saving model to best_model.h5\n",
            "Epoch 36/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 1.8261"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 423us/step - loss: 2.0045\n",
            "\n",
            "Epoch 00036: loss improved from 2.05444 to 2.00453, saving model to best_model.h5\n",
            "Epoch 37/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.8009"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 423us/step - loss: 1.9560\n",
            "\n",
            "Epoch 00037: loss improved from 2.00453 to 1.95596, saving model to best_model.h5\n",
            "Epoch 38/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 1.7365"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 423us/step - loss: 1.9211\n",
            "\n",
            "Epoch 00038: loss improved from 1.95596 to 1.92106, saving model to best_model.h5\n",
            "Epoch 39/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.7545"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 1.8807\n",
            "\n",
            "Epoch 00039: loss improved from 1.92106 to 1.88074, saving model to best_model.h5\n",
            "Epoch 40/100\n",
            " 16128/137995 [==>...........................] - ETA: 50s - loss: 1.6929"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 421us/step - loss: 1.8426\n",
            "\n",
            "Epoch 00040: loss improved from 1.88074 to 1.84261, saving model to best_model.h5\n",
            "Epoch 41/100\n",
            " 16000/137995 [==>...........................] - ETA: 51s - loss: 1.6569"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 418us/step - loss: 1.8116\n",
            "\n",
            "Epoch 00041: loss improved from 1.84261 to 1.81156, saving model to best_model.h5\n",
            "Epoch 42/100\n",
            " 16256/137995 [==>...........................] - ETA: 50s - loss: 1.6187"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 419us/step - loss: 1.7712\n",
            "\n",
            "Epoch 00042: loss improved from 1.81156 to 1.77121, saving model to best_model.h5\n",
            "Epoch 43/100\n",
            " 16384/137995 [==>...........................] - ETA: 51s - loss: 1.5774"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 421us/step - loss: 1.7458\n",
            "\n",
            "Epoch 00043: loss improved from 1.77121 to 1.74584, saving model to best_model.h5\n",
            "Epoch 44/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.5636"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 1.7128\n",
            "\n",
            "Epoch 00044: loss improved from 1.74584 to 1.71281, saving model to best_model.h5\n",
            "Epoch 45/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.5432"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 418us/step - loss: 1.6868\n",
            "\n",
            "Epoch 00045: loss improved from 1.71281 to 1.68684, saving model to best_model.h5\n",
            "Epoch 46/100\n",
            " 16256/137995 [==>...........................] - ETA: 50s - loss: 1.5174"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 418us/step - loss: 1.6600\n",
            "\n",
            "Epoch 00046: loss improved from 1.68684 to 1.65996, saving model to best_model.h5\n",
            "Epoch 47/100\n",
            " 16128/137995 [==>...........................] - ETA: 50s - loss: 1.4793"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 418us/step - loss: 1.6331\n",
            "\n",
            "Epoch 00047: loss improved from 1.65996 to 1.63312, saving model to best_model.h5\n",
            "Epoch 48/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 1.4759"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 420us/step - loss: 1.6073\n",
            "\n",
            "Epoch 00048: loss improved from 1.63312 to 1.60730, saving model to best_model.h5\n",
            "Epoch 49/100\n",
            " 16128/137995 [==>...........................] - ETA: 50s - loss: 1.4734"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 421us/step - loss: 1.5894\n",
            "\n",
            "Epoch 00049: loss improved from 1.60730 to 1.58938, saving model to best_model.h5\n",
            "Epoch 50/100\n",
            " 16000/137995 [==>...........................] - ETA: 51s - loss: 1.4210"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 1.5622\n",
            "\n",
            "Epoch 00050: loss improved from 1.58938 to 1.56220, saving model to best_model.h5\n",
            "Epoch 51/100\n",
            " 16000/137995 [==>...........................] - ETA: 51s - loss: 1.3763"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 424us/step - loss: 1.5385\n",
            "\n",
            "Epoch 00051: loss improved from 1.56220 to 1.53854, saving model to best_model.h5\n",
            "Epoch 52/100\n",
            " 16384/137995 [==>...........................] - ETA: 51s - loss: 1.3835"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 423us/step - loss: 1.5278\n",
            "\n",
            "Epoch 00052: loss improved from 1.53854 to 1.52782, saving model to best_model.h5\n",
            "Epoch 53/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.3600"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 1.5057\n",
            "\n",
            "Epoch 00053: loss improved from 1.52782 to 1.50572, saving model to best_model.h5\n",
            "Epoch 54/100\n",
            " 16256/137995 [==>...........................] - ETA: 50s - loss: 1.3548"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 1.4859\n",
            "\n",
            "Epoch 00054: loss improved from 1.50572 to 1.48593, saving model to best_model.h5\n",
            "Epoch 55/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 1.3338"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 1.4628\n",
            "\n",
            "Epoch 00055: loss improved from 1.48593 to 1.46281, saving model to best_model.h5\n",
            "Epoch 56/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 1.3104"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 419us/step - loss: 1.4488\n",
            "\n",
            "Epoch 00056: loss improved from 1.46281 to 1.44880, saving model to best_model.h5\n",
            "Epoch 57/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.3167"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 1.4381\n",
            "\n",
            "Epoch 00057: loss improved from 1.44880 to 1.43808, saving model to best_model.h5\n",
            "Epoch 58/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 1.2949"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 423us/step - loss: 1.4168\n",
            "\n",
            "Epoch 00058: loss improved from 1.43808 to 1.41684, saving model to best_model.h5\n",
            "Epoch 59/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.2694"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 1.4036\n",
            "\n",
            "Epoch 00059: loss improved from 1.41684 to 1.40362, saving model to best_model.h5\n",
            "Epoch 60/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 1.2612"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 424us/step - loss: 1.3884\n",
            "\n",
            "Epoch 00060: loss improved from 1.40362 to 1.38837, saving model to best_model.h5\n",
            "Epoch 61/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.2431"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 417us/step - loss: 1.3798\n",
            "\n",
            "Epoch 00061: loss improved from 1.38837 to 1.37984, saving model to best_model.h5\n",
            "Epoch 62/100\n",
            " 16384/137995 [==>...........................] - ETA: 50s - loss: 1.2339"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 418us/step - loss: 1.3723\n",
            "\n",
            "Epoch 00062: loss improved from 1.37984 to 1.37228, saving model to best_model.h5\n",
            "Epoch 63/100\n",
            " 16128/137995 [==>...........................] - ETA: 50s - loss: 1.2205"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 57s 416us/step - loss: 1.3542\n",
            "\n",
            "Epoch 00063: loss improved from 1.37228 to 1.35424, saving model to best_model.h5\n",
            "Epoch 64/100\n",
            " 16384/137995 [==>...........................] - ETA: 51s - loss: 1.2173"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 1.3392\n",
            "\n",
            "Epoch 00064: loss improved from 1.35424 to 1.33918, saving model to best_model.h5\n",
            "Epoch 65/100\n",
            " 16384/137995 [==>...........................] - ETA: 51s - loss: 1.2073"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 424us/step - loss: 1.3283\n",
            "\n",
            "Epoch 00065: loss improved from 1.33918 to 1.32831, saving model to best_model.h5\n",
            "Epoch 66/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.2042"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 424us/step - loss: 1.3150\n",
            "\n",
            "Epoch 00066: loss improved from 1.32831 to 1.31504, saving model to best_model.h5\n",
            "Epoch 67/100\n",
            " 16384/137995 [==>...........................] - ETA: 50s - loss: 1.1969"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 424us/step - loss: 1.3129\n",
            "\n",
            "Epoch 00067: loss improved from 1.31504 to 1.31287, saving model to best_model.h5\n",
            "Epoch 68/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 1.1986"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 423us/step - loss: 1.2999\n",
            "\n",
            "Epoch 00068: loss improved from 1.31287 to 1.29988, saving model to best_model.h5\n",
            "Epoch 69/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 1.1881"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 426us/step - loss: 1.2953\n",
            "\n",
            "Epoch 00069: loss improved from 1.29988 to 1.29530, saving model to best_model.h5\n",
            "Epoch 70/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 1.1602"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 425us/step - loss: 1.2803\n",
            "\n",
            "Epoch 00070: loss improved from 1.29530 to 1.28027, saving model to best_model.h5\n",
            "Epoch 71/100\n",
            " 16000/137995 [==>...........................] - ETA: 52s - loss: 1.1457"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 425us/step - loss: 1.2719\n",
            "\n",
            "Epoch 00071: loss improved from 1.28027 to 1.27193, saving model to best_model.h5\n",
            "Epoch 72/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.1410"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 425us/step - loss: 1.2649\n",
            "\n",
            "Epoch 00072: loss improved from 1.27193 to 1.26491, saving model to best_model.h5\n",
            "Epoch 73/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 1.1438"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 425us/step - loss: 1.2502\n",
            "\n",
            "Epoch 00073: loss improved from 1.26491 to 1.25019, saving model to best_model.h5\n",
            "Epoch 74/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 1.1231"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 425us/step - loss: 1.2405\n",
            "\n",
            "Epoch 00074: loss improved from 1.25019 to 1.24047, saving model to best_model.h5\n",
            "Epoch 75/100\n",
            " 16128/137995 [==>...........................] - ETA: 52s - loss: 1.1224"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 425us/step - loss: 1.2328\n",
            "\n",
            "Epoch 00075: loss improved from 1.24047 to 1.23282, saving model to best_model.h5\n",
            "Epoch 76/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.0907"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 425us/step - loss: 1.2171\n",
            "\n",
            "Epoch 00076: loss improved from 1.23282 to 1.21715, saving model to best_model.h5\n",
            "Epoch 77/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.1168"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 426us/step - loss: 1.2227\n",
            "\n",
            "Epoch 00077: loss did not improve\n",
            "Epoch 78/100\n",
            " 20224/137995 [===>..........................] - ETA: 50s - loss: 1.1061"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 426us/step - loss: 1.2117\n",
            "\n",
            "Epoch 00078: loss improved from 1.21715 to 1.21173, saving model to best_model.h5\n",
            "Epoch 79/100\n",
            " 17280/137995 [==>...........................] - ETA: 51s - loss: 1.1086"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 426us/step - loss: 1.2054\n",
            "\n",
            "Epoch 00079: loss improved from 1.21173 to 1.20544, saving model to best_model.h5\n",
            "Epoch 80/100\n",
            " 16384/137995 [==>...........................] - ETA: 51s - loss: 1.0816"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 424us/step - loss: 1.1942\n",
            "\n",
            "Epoch 00080: loss improved from 1.20544 to 1.19425, saving model to best_model.h5\n",
            "Epoch 81/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.0984"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 423us/step - loss: 1.1918\n",
            "\n",
            "Epoch 00081: loss improved from 1.19425 to 1.19177, saving model to best_model.h5\n",
            "Epoch 82/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.0691"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 422us/step - loss: 1.1850\n",
            "\n",
            "Epoch 00082: loss improved from 1.19177 to 1.18501, saving model to best_model.h5\n",
            "Epoch 83/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.0753"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 424us/step - loss: 1.1791\n",
            "\n",
            "Epoch 00083: loss improved from 1.18501 to 1.17905, saving model to best_model.h5\n",
            "Epoch 84/100\n",
            " 16256/137995 [==>...........................] - ETA: 51s - loss: 1.0473"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 421us/step - loss: 1.1676\n",
            "\n",
            "Epoch 00084: loss improved from 1.17905 to 1.16758, saving model to best_model.h5\n",
            "Epoch 85/100\n",
            " 16256/137995 [==>...........................] - ETA: 50s - loss: 1.0598"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 420us/step - loss: 1.1711\n",
            "\n",
            "Epoch 00085: loss did not improve\n",
            "Epoch 86/100\n",
            " 20480/137995 [===>..........................] - ETA: 49s - loss: 1.0625"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 424us/step - loss: 1.1640\n",
            "\n",
            "Epoch 00086: loss improved from 1.16758 to 1.16399, saving model to best_model.h5\n",
            "Epoch 87/100\n",
            " 17280/137995 [==>...........................] - ETA: 51s - loss: 1.0484"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 424us/step - loss: 1.1527\n",
            "\n",
            "Epoch 00087: loss improved from 1.16399 to 1.15273, saving model to best_model.h5\n",
            "Epoch 88/100\n",
            " 16512/137995 [==>...........................] - ETA: 51s - loss: 1.0487"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 425us/step - loss: 1.1486\n",
            "\n",
            "Epoch 00088: loss improved from 1.15273 to 1.14856, saving model to best_model.h5\n",
            "Epoch 89/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 1.0072"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 425us/step - loss: 1.1291\n",
            "\n",
            "Epoch 00089: loss improved from 1.14856 to 1.12914, saving model to best_model.h5\n",
            "Epoch 90/100\n",
            " 16128/137995 [==>...........................] - ETA: 51s - loss: 1.0530"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 424us/step - loss: 1.1454\n",
            "\n",
            "Epoch 00090: loss did not improve\n",
            "Epoch 91/100\n",
            " 20096/137995 [===>..........................] - ETA: 49s - loss: 1.0313"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 424us/step - loss: 1.1369\n",
            "\n",
            "Epoch 00091: loss did not improve\n",
            "Epoch 92/100\n",
            " 21632/137995 [===>..........................] - ETA: 49s - loss: 1.0296"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 424us/step - loss: 1.1239\n",
            "\n",
            "Epoch 00092: loss improved from 1.12914 to 1.12386, saving model to best_model.h5\n",
            "Epoch 93/100\n",
            " 17792/137995 [==>...........................] - ETA: 50s - loss: 1.0143"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 423us/step - loss: 1.1242\n",
            "\n",
            "Epoch 00093: loss did not improve\n",
            "Epoch 94/100\n",
            " 20992/137995 [===>..........................] - ETA: 49s - loss: 0.9951"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 424us/step - loss: 1.1107\n",
            "\n",
            "Epoch 00094: loss improved from 1.12386 to 1.11072, saving model to best_model.h5\n",
            "Epoch 95/100\n",
            " 17664/137995 [==>...........................] - ETA: 50s - loss: 1.0356"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 423us/step - loss: 1.1230\n",
            "\n",
            "Epoch 00095: loss did not improve\n",
            "Epoch 96/100\n",
            " 20992/137995 [===>..........................] - ETA: 49s - loss: 1.0121"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 425us/step - loss: 1.1061\n",
            "\n",
            "Epoch 00096: loss improved from 1.11072 to 1.10606, saving model to best_model.h5\n",
            "Epoch 97/100\n",
            " 17536/137995 [==>...........................] - ETA: 51s - loss: 1.0340"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 424us/step - loss: 1.1073\n",
            "\n",
            "Epoch 00097: loss did not improve\n",
            "Epoch 98/100\n",
            " 20608/137995 [===>..........................] - ETA: 50s - loss: 0.9898"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 424us/step - loss: 1.1000\n",
            "\n",
            "Epoch 00098: loss improved from 1.10606 to 1.10004, saving model to best_model.h5\n",
            "Epoch 99/100\n",
            " 17536/137995 [==>...........................] - ETA: 50s - loss: 0.9795"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 58s 424us/step - loss: 1.1032\n",
            "\n",
            "Epoch 00099: loss did not improve\n",
            "Epoch 100/100\n",
            " 20608/137995 [===>..........................] - ETA: 49s - loss: 1.0120"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137995/137995 [==============================] - 59s 427us/step - loss: 1.0948\n",
            "\n",
            "Epoch 00100: loss improved from 1.10004 to 1.09481, saving model to best_model.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f986ff0e7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "R8M3wqzeSPFv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('best_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_O9MUjvXZhZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model=load_model('best_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lQNpRjWGXjZc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "def generate_seq(model, seq_length, seed_text, n_words):\n",
        "    result = list()\n",
        "    in_text = seed_text\n",
        "    # generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "      encoded=[]\n",
        "      # encode the text as integer\n",
        "      for word in in_text.split():\n",
        "        encoded.append(vocab_to_int[word])\n",
        "      # truncate sequences to a fixed length\n",
        "      encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "      # predict probabilities for each word\n",
        "      yhat = model.predict_classes(encoded, verbose=0)\n",
        "      # map predicted word index to word\n",
        "      out_word = ''\n",
        "      for word, index in vocab_to_int.items():\n",
        "        if index == yhat:\n",
        "          out_word = word\n",
        "          break\n",
        "      # append to input\n",
        "      in_text += ' ' + out_word\n",
        "      result.append(out_word)\n",
        "    return ' '.join(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lUQL7R6CaoBj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e3e136b0-49de-4e12-a3bb-8f0282968751",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524300165980,
          "user_tz": 420,
          "elapsed": 16101,
          "user": {
            "displayName": "Arun Rajendran",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "100710189298922321078"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "seed=' '.join(tokens[:100])\n",
        "generated = generate_seq(model,seq_len,seed,1000)\n",
        "print(generated)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a moment gasping for breath taking stock i am still alive he crawled out from under the canvas and scanned the cavernous space for someplace to hide a voice spoke chillingly close do not move on the floor and then it is the knights thing of the priory of sion and the grail that is the holy grail that the documents simply had been told the grail in the chapel she was certain he had just yet the line of the painful fallingout she was not in the moment he thought she had been given the teacher to the end of days a little sophie and be finished in the side of the church and a lone thought of wine and the most feminine of this of the most world the holy grail is a grail but when the documents documents a knight that the grail stopped at the tomb of the french police langdon looked back at the mona lisa before the door im a message with the keystone he felt a startled and that news teabing had been often in the hurry of the priory and yet the true man was not being one is the holy grail is a man the priory has always been the grail in the bank the grail has been a clear of the priory of sion that the church is the grail and mary magdalene the holy grail is the one sequence it was the key to me the holy grail is a woman the last supper is a painting of thirteen men is it teabing arched his eyebrows take a closer in the moment he felt a deep breath and yet the priory of sion had been the holy grail the grail is the holy grail langdon said as i mentioned your men to the right the keystone are out out in the darkness he was a little within that feared the priory of sion we will be written about the brotherhood are not a good man now he had told the grail to himself the grail is the holy grail langdon said again it was to the own symbols and then the knights of the goddess the rose of the rose and female and all the doors of the keystone was in an instant its dark a bank of this abbey the man of the holy grail is a cup of mary magdalene and the priory of sion the grail that the priory was mary magdalene and the holy grail the priory and sion the church did the brotherhoods documents have the holy grail the priorys treasure royal treasure made all all of the priory of the sacred feminine but the sacred feminine teabing is the holy grail of the brotherhoods christ and you will be you that that the teacher said her eyes is to me you have a lot to know you will help me enough this to be on the room before the slip of paper was still when langdon could the idea of that what is the holy grail is a legend to trust you are a knight to honor at the last end of the church but it was a fortress in the box it was not a good message one of the gospels of mary magdalene and the knights templar of the royal grail of the priory of sion and the holy grail is the cup of christ and all the documents that is the grail to the holy grail the true man of the holy grail sophie had been far in a long unlikely but in those da vinci botticelli a year prelature with the priory of sion the church was a symbolic of stone subjugated and the same church the rose of the goddess mary magdalene was the holy grail the priory and the grail you is it is that or that because but they were a little more than a angel of the pope in the sacred feminine of the louvre the rose templar king power and the early knights for the holy grail the rose of the tomb was not the secret of sion aringarosa said is a very dont i am not a man to you i have a problem to do you you need to ask the grail is you that you know to do you know your grandfather is trying to reach me you wasnt a very more now that he said langdon said her was english in the french of the church she had been surprised of all that had been him at the first half as the word on the rose house was no kind of mary magdalene the truth of the holy grail and that was a word grand master when the grail had been going to be the grail the priory of sion has a one and sion he had been seen the man walls now with a taunting wariness and a pope where the church had been almost used in by the way of jesus and i will you want you to me to meet for you tell me the keystone that i dont know the grail is you to you not the holy grail is a cup langdon thought the church is the only of venus of the sacred feminine the pope the priory of the goddess was almost european and the most right in the temple church is on the ruins of the gallery he paused if langdon was looking in a woman she had no idea even to respond he was not not sure that they were met of the french agents that had been been by the truth in the holy grail the priory of sion we would not possibly all before langdon turned to sophie who to the grail in the french police do he had a point about the key to the vault he paused the sequence teabing could not be only to tell the first\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}